{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kerchunk and Xarray-Datatree"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "In this tutorial we are going to use a large collection of pre-generated `Kerchunk` reference files and open them with [xarray-datatree](https://xarray-datatree.readthedocs.io/en/latest/). This chapter is heavily inspired by [this blog post](https://medium.com/pangeo/easy-ipcc-part-1-multi-model-datatree-469b87cf9114).\n",
    "\n",
    "\n",
    "\n",
    "### About the Dataset\n",
    "\n",
    "This collection of reference files were generated from the [**NASA NEX-GDDP-CMIP6 (Global Daily Downscaled Projections)**](https://www.nccs.nasa.gov/services/data-collections/land-based-products/nex-gddp-cmip6) dataset.  A version of this dataset is hosted on `s3` as a collection of [NetCDF files](https://registry.opendata.aws/nex-gddp-cmip6/). \n",
    "\n",
    "\n",
    "## Prerequisites\n",
    "| Concepts | Importance | Notes |\n",
    "| --- | --- | --- |\n",
    "| [Kerchunk Basics](../foundations/kerchunk_basics) | Required | Core |\n",
    "| [Multiple Files and Kerchunk](../foundations/kerchunk_multi_file) | Required | Core |\n",
    "| [Kerchunk and Dask](../foundations/kerchunk_dask) | Required | Core |\n",
    "| [Multi-File Datasets with Kerchunk](../case_studies/ARG_Weather.ipynb) | Required | IO/Visualization |\n",
    "| [Xarray-Datatree Overview](https://xarray-datatree.readthedocs.io/en/latest/quick-overview.html)| Required | IO |\n",
    "\n",
    "- **Time to learn**: 30 minutes\n",
    "\n",
    "## Motivation\n",
    "\n",
    "In total the dataset is roughly **12TB** in compressed blob storage, with a single `NetCDF` file per yearly timestep, per variable. Downloading this entire dataset for analysis on a local machine would difficult to say the least. The collection of `Kerchunk` reference files for this entire dataset is only **272 Mb**, which is about 42,000 times smaller! "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "import hvplot.xarray  # noqa\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from datatree import DataTree\n",
    "from distributed import Client\n",
    "from fsspec.implementations.reference import ReferenceFileSystem"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the reference catalog\n",
    "\n",
    "The **NASA NEX-GDDP-CMIP6** dataset is organized by GCM, Scenario and Ensemble Member. Each of these Scenario/GCM combinations is represented as a combined reference file, which was created by merging across variables and concatenating along time-steps. All of these references are organized into a simple `.csv` catalog in the schema: \n",
    "|   GCM/Scenario  |      url    |\n",
    "| --------------- | ----------- |\n",
    "\n",
    "\n",
    "# Organzing with Xarray-Datatree\n",
    "Not all of the GCM/Scenario reference datasets have shared spatial coordinates and many of the have slight differences in their calendar and thus time dimension. \n",
    "Because of this, these cannot be combined into a single `Xarray-Dataset`. Fortunately `Xarray-Datatree` provides a higher level abstraction where related `Xarray-Datasets` are organized into a tree structure where each dataset corresponds to a `leaf`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the reference catalog into a Pandas DataFrame\n",
    "cat_df = pd.read_csv(\n",
    "    \"s3://carbonplan-share/nasa-nex-reference/reference_catalog_nested.csv\"\n",
    ")\n",
    "# Convert the DataFrame into a dictionary\n",
    "catalog = cat_df.set_index(\"ID\").T.to_dict(\"records\")[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Reference Datasets into Xarray-DataTree\n",
    "\n",
    "In the following cell we create a function `load_ref_ds`, which can be parallelized via `Dask` to load `Kerchunk` references into a dictionary of `Xarray-Datasets`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ref_ds(url: str):\n",
    "    fs = ReferenceFileSystem(\n",
    "        url,\n",
    "        remote_protocol=\"s3\",\n",
    "        target_protocol=\"s3\",\n",
    "        remote_options={\"anon\": True},\n",
    "        target_options={\"anon\": True},\n",
    "        lazy=True,\n",
    "    )\n",
    "    return xr.open_dataset(\n",
    "        fs.get_mapper(),\n",
    "        engine=\"zarr\",\n",
    "        backend_kwargs={\"consolidated\": False},\n",
    "        chunks={\"time\": 300},\n",
    "    )\n",
    "\n",
    "\n",
    "tasks = {id: dask.delayed(load_ref_ds)(url) for id, url in catalog.items()}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Dask Distributed to load the Xarray-Datasets from Kerchunk reference files\n",
    "Using `Dask`, we are loading 164 reference datasets into memory. Since they are are `Xarray` datasets the coordinates are loaded eagerly, but the underlying data is still lazy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(n_workers=8)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog_computed = dask.compute(tasks)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build an Xarray-Datatree from the dictionary of datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DataTree.from_dict(catalog_computed[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing the Datatree\n",
    "\n",
    "A `Datatree` is a collection of related `Xarray` datasets. We can access individual datasets using `UNIX` syntax. In the cell below, we will access a single dataset from the `datatree`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt[\"ACCESS-CM2/ssp585\"]\n",
    "\n",
    "# or\n",
    "\n",
    "dt[\"ACCESS-CM2\"][\"ssp585\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert a Datatree node to a Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt[\"ACCESS-CM2\"][\"ssp585\"].to_dataset()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operations across a Datatree\n",
    "A `Datatree` contains a collection of datasets with related coordinates and variables. Using some in-built methods, we can analyze it as if it were a single dataset. Instead of looping through hundreds of `Xarray` datasets, we can apply operations across the `Datatree`. In the example below, we will lazily create a time-series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = dt.mean(dim=[\"lat\", \"lon\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize a single dataset with HvPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(  # noqa\n",
    "    dt[\"ACCESS-CM2/ssp585\"].to_dataset().pr.hvplot(\"lon\", \"lat\", rasterize=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shut down the Dask cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
