{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GeoTIFF\n",
    "Generating Kerchunk References from GeoTIFF files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/radar.png\" width=400 alt=\"ARG\"></img>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "In this tutorial we will cover:\n",
    "\n",
    "1. How to generate `Kerchunk` references of GeoTIFFs.\n",
    "1. Combining `Kerchunk` references into a virtual dataset.\n",
    "\n",
    "\n",
    "## Prerequisites\n",
    "| Concepts | Importance | Notes |\n",
    "| --- | --- | --- |\n",
    "| [Kerchunk Basics](../foundations/kerchunk_basics) | Required | Core |\n",
    "| [Multiple Files and Kerchunk](../foundations/kerchunk_multi_file) | Required | Core |\n",
    "| [Kerchunk and Dask](../foundations/kerchunk_dask) | Required | Core |\n",
    "| [Introduction to Xarray](https://foundations.projectpythia.org/core/xarray/xarray-intro.html) | Required | IO/Visualization |\n",
    "- **Time to learn**: 30 minutes\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the Dataset\n",
    "\n",
    "The Finish Meterological Institute (FMI) Weather Radar Dataset is a collection of GeoTIFF files containing multiple radar specific variables, such as rainfall intensity, precipitation accumulation (in 1, 12 and 24 hour increments),  radar reflectivity, radial velocity, rain classification and the cloud top height. It is available through the [AWS public data portal](https://aws.amazon.com/marketplace/pp/prodview-koodet467asui?sr=0-19&ref_=beagle&applicationId=AWSMPContessa) and is updated frequently. \n",
    "\n",
    "\n",
    "\n",
    "More details on this dataset can be found [here](https://en.ilmatieteenlaitos.fi/radar-data-on-aws-s3).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import logging\n",
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "import dask\n",
    "import fsspec\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rioxarray\n",
    "import s3fs\n",
    "import ujson\n",
    "import xarray as xr\n",
    "from distributed import Client\n",
    "from kerchunk.combine import MultiZarrToZarr\n",
    "from kerchunk.tiff import tiff_to_zarr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examining a Single GeoTIFF File\n",
    "\n",
    "Before we use `Kerchunk` to create indices for multiple files, we can load a single GeoTiff file to examine it. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL pointing to a single GeoTIFF file\n",
    "url = \"s3://fmi-opendata-radar-geotiff/2023/07/01/FIN-ACRR-3067-1KM/202307010100_FIN-ACRR1H-3067-1KM.tif\"\n",
    "\n",
    "# Initialize a s3 filesystem\n",
    "fs = s3fs.S3FileSystem(anon=True)\n",
    "\n",
    "xds = rioxarray.open_rasterio(fs.open(url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xds.isel(band=0).where(xds < 2000).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Input File List\n",
    "\n",
    "Here we are using `fsspec's` glob functionality along with the *`*`* wildcard operator and some string slicing to grab a list of GeoTIFF files from a `s3` `fsspec` filesystem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate fsspec filesystems for reading\n",
    "fs_read = fsspec.filesystem(\"s3\", anon=True, skip_instance_cache=True)\n",
    "\n",
    "files_paths = fs_read.glob(\n",
    "    \"s3://fmi-opendata-radar-geotiff/2023/01/01/FIN-ACRR-3067-1KM/*24H-3067-1KM.tif\"\n",
    ")\n",
    "# Here we prepend the prefix 's3://', which points to AWS.\n",
    "file_pattern = sorted([\"s3://\" + f for f in files_paths])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This dictionary will be passed as kwargs to `fsspec`. For more details, check out the `foundations/kerchunk_basics` notebook.\n",
    "so = dict(mode=\"rb\", anon=True, default_fill_cache=False, default_cache_type=\"first\")\n",
    "\n",
    "# We are creating a temporary directory to store the .json reference files\n",
    "# Alternately, you could write these to cloud storage.\n",
    "td = TemporaryDirectory()\n",
    "temp_dir = td.name\n",
    "temp_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start a Dask Client\n",
    "\n",
    "To parallelize the creation of our reference files, we will use `Dask`. For a detailed guide on how to use Dask and Kerchunk, see the Foundations notebook: [Kerchunk and Dask](../foundations/kerchunk_dask).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(n_workers=8, silence_logs=logging.ERROR)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Kerchunk's `tiff_to_zarr` method to create create reference files\n",
    "\n",
    "\n",
    "def generate_json_reference(fil, output_dir: str):\n",
    "    tiff_chunks = tiff_to_zarr(fil, remote_options={\"protocol\": \"s3\", \"anon\": True})\n",
    "    fname = fil.split(\"/\")[-1].split(\"_\")[0]\n",
    "    outf = f\"{output_dir}/{fname}.json\"\n",
    "    with open(outf, \"wb\") as f:\n",
    "        f.write(ujson.dumps(tiff_chunks).encode())\n",
    "    return outf\n",
    "\n",
    "\n",
    "# Generate Dask Delayed objects\n",
    "tasks = [dask.delayed(generate_json_reference)(fil, temp_dir) for fil in file_pattern]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start parallel processing\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "dask.compute(tasks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine Reference Files into Multi-File Reference Dataset\n",
    "\n",
    "Now we will combine all the reference files generated into a single reference dataset. Since each TIFF file is a single timeslice and the only temporal information is stored in the filepath, we will have to specify the `coo_map` kwarg in `MultiZarrToZarr` to build a dimension from the filepath attributes. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_files = sorted(glob.iglob(f\"{temp_dir}/*.json\"))\n",
    "\n",
    "\n",
    "# Custom Kerchunk function from `coo_map` to create dimensions\n",
    "def fn_to_time(index, fs, var, fn):\n",
    "    import datetime\n",
    "    import re\n",
    "\n",
    "    subst = fn.split(\"/\")[-1].split(\".json\")[0]\n",
    "    return datetime.datetime.strptime(subst, \"%Y%m%d%H%M\")\n",
    "\n",
    "\n",
    "mzz = MultiZarrToZarr(\n",
    "    path=ref_files,\n",
    "    indicts=ref_files,\n",
    "    remote_protocol=\"s3\",\n",
    "    remote_options={\"anon\": True},\n",
    "    coo_map={\"time\": fn_to_time},\n",
    "    coo_dtypes={\"time\": np.dtype(\"M8[s]\")},\n",
    "    concat_dims=[\"time\"],\n",
    "    identical_dims=[\"X\", \"Y\"],\n",
    ")\n",
    "\n",
    "# # save translate reference in memory for later visualization\n",
    "multi_kerchunk = mzz.translate()\n",
    "\n",
    "# Write kerchunk .json record\n",
    "output_fname = \"RADAR.json\"\n",
    "with open(f\"{output_fname}\", \"wb\") as f:\n",
    "    f.write(ujson.dumps(multi_kerchunk).encode())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
