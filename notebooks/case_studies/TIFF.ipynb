{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kerchunk, GeoTIFF and Generating Coordinates with `xrefcoord`\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/silo.png\" width=400 alt=\"ARG\"></img>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "In this tutorial we will cover:\n",
    "\n",
    "1. How to generate `Kerchunk` references of GeoTIFFs.\n",
    "1. Combining `Kerchunk` references into a virtual dataset.\n",
    "1. Generating Coordinates with the `xrefcoord` accessor.\n",
    "\n",
    "\n",
    "## Prerequisites\n",
    "| Concepts | Importance | Notes |\n",
    "| --- | --- | --- |\n",
    "| [Kerchunk Basics](../foundations/kerchunk_basics) | Required | Core |\n",
    "| [Multiple Files and Kerchunk](../foundations/kerchunk_multi_file) | Required | Core |\n",
    "| [Kerchunk and Dask](../foundations/kerchunk_dask) | Required | Core |\n",
    "| [Introduction to Xarray](https://foundations.projectpythia.org/core/xarray/xarray-intro.html) | Required | IO/Visualization |\n",
    "- **Time to learn**: 30 minutes\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivation\n",
    "\n",
    "GeoTIFF\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the Dataset\n",
    "\n",
    "SILO is an Australian climate dataset ranging from 1889-present. It contains daily and aggregated climate fields in both NetCDF and GeoTIFF formats. A version of it is hosted on the Registry of Open Data on AWS.\n",
    "\n",
    "More details on this dataset can be found [here](https://registry.opendata.aws/silo/) and [here](https://www.longpaddock.qld.gov.au/silo/).\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flags\n",
    "In the section below, set the `subset` flag to be `True` (default) or `False` depending if you want this notebook to process the full file list. If set to `True`, then a subset of the file list will be processed (Recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_flag = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import logging\n",
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "import dask\n",
    "import fsspec\n",
    "import numpy as np\n",
    "# import xrefcoord  # noqa\n",
    "import rioxarray\n",
    "import s3fs\n",
    "import ujson\n",
    "import xarray as xr\n",
    "from distributed import Client\n",
    "from kerchunk.combine import MultiZarrToZarr\n",
    "from kerchunk.tiff import tiff_to_zarr\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examining a Single GeoTIFF File\n",
    "\n",
    "Before we use `Kerchunk` to create indices for multiple files, we can load a single GeoTiff file to examine it. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL pointing to a single NetCDF file\n",
    "url = \"s3://silo-open-data/Recommended/daily/daily_rain/2023/20230711.daily_rain.tif\"\n",
    "\n",
    "# Initialize a s3 filesystem\n",
    "fs = s3fs.S3FileSystem(anon=True)\n",
    "\n",
    "xds = rioxarray.open_rasterio(fs.open(url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xds"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Input File List\n",
    "\n",
    "Here we are using `fsspec's` glob functionality along with the *`*`* wildcard operator and some string slicing to grab a list of GeoTIFF files from a `s3` `fsspec` filesystem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate fsspec filesystems for reading\n",
    "fs_read = fsspec.filesystem(\"s3\", anon=True, skip_instance_cache=True)\n",
    "\n",
    "file_paths = fs_read.glob(\"s3://silo-open-data/Recommended/daily/daily_rain/2023/*\")\n",
    "\n",
    "# Here we prepend the prefix 's3://', which points to AWS.\n",
    "file_pattern = sorted([\"s3://\" + f for f in file_paths])\n",
    "\n",
    "\n",
    "# If the subset_flag == True (default), the list of input files will be subset to speed up the processing\n",
    "if subset_flag:\n",
    "    file_pattern = file_pattern[0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This dictionary will be passed as kwargs to `fsspec`. For more details, check out the `foundations/kerchunk_basics` notebook.\n",
    "so = dict(mode=\"rb\", anon=True, default_fill_cache=False, default_cache_type=\"first\")\n",
    "\n",
    "# We are creating a temporary directory to store the .json reference files\n",
    "# Alternately, you could write these to cloud storage.\n",
    "td = TemporaryDirectory()\n",
    "temp_dir = td.name\n",
    "temp_dir"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start a Dask Client\n",
    "\n",
    "To parallelize the creation of our reference files, we will use `Dask`. For a detailed guide on how to use Dask and Kerchunk, see the Foundations notebook: [Kerchunk and Dask](../foundations/kerchunk_dask).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(n_workers=8, silence_logs=logging.ERROR)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Kerchunk's `tiff_to_zarr` method to create create reference files\n",
    "\n",
    "\n",
    "def generate_json_reference(fil, output_dir: str):\n",
    "    tiff_chunks = tiff_to_zarr(fil, remote_options={\"protocol\": \"s3\"})\n",
    "    fname = fil.split(\"/\")[-2]\n",
    "    outf = f\"{output_dir}/{fname}.json\"\n",
    "    with open(outf, \"wb\") as f:\n",
    "        f.write(ujson.dumps(tiff_chunks).encode())\n",
    "    return outf\n",
    "\n",
    "\n",
    "# Generate Dask Delayed objects\n",
    "tasks = [dask.delayed(generate_json_reference)(fil, temp_dir) for fil in file_pattern]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start parallel processing\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "dask.compute(tasks)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine Reference Files into Multi-File Reference Dataset\n",
    "\n",
    "Now we will combine all the reference files generated into a single reference dataset. Since each TIFF file is a single timeslice and the only temporal information is stored in the filepath, we will have to specify the `coo_map` kwarg in `MultiZarrToZarr` to build a dimension from the filepath attributes. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Kerchunk function from `coo_map` to create dimensions\n",
    "def fn_to_time(index, fs, var, fn):\n",
    "    import datetime\n",
    "    import re\n",
    "\n",
    "    subst = fn.split(\"/\")[-2].split(\"_\")[2]\n",
    "    return datetime.datetime.strptime(subst, \"%Y%m%d\")\n",
    "\n",
    "\n",
    "mzz = MultiZarrToZarr(\n",
    "    path=file_paths,\n",
    "    indicts=sorted(glob.iglob(f\"{temp_dir}/*.json\")),\n",
    "    remote_protocol=\"s3\",\n",
    "    coo_map={\"time\": fn_to_time},\n",
    "    coo_dtypes={\"time\": np.dtype(\"M8[s]\")},\n",
    "    concat_dims=[\"time\"],\n",
    "    identical_dims=[\"x\", \"y\"],\n",
    ")\n",
    "\n",
    "# save translate reference in memory for later visualization\n",
    "multi_kerchunk = mzz.translate()\n",
    "\n",
    "# Write kerchunk .json record\n",
    "output_fname = \"SILO.json\"\n",
    "with open(f\"{output_fname}\", \"wb\") as f:\n",
    "    f.write(ujson.dumps(multi_kerchunk).encode())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open Combined Reference Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = fsspec.filesystem(\n",
    "    \"reference\",\n",
    "    fo=\"SILO.json\",\n",
    "    remote_protocol=\"s3\",\n",
    "    remote_options={\"anon\": True},\n",
    "    skip_instance_cache=True,\n",
    ")\n",
    "m = fs.get_mapper(\"\")\n",
    "ds = xr.open_dataset(m, engine=\"zarr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use `xrefcoord` to Generate Coordinates\n",
    "When using `Kerchunk` to generate reference datasets for GeoTIFF's, only the dimensions are preserved. `xrefcoord` is a small utility that allows us to generate coordinates for these reference datasets using the geospatial metadata. Similar to other accessor add-on libraries for `Xarray` such as `rioxarray` and `xwrf`, `xrefcord` provides an accessor for an `Xarray` dataset. Importing `xrefcoord` allows us to use the `.xref` accessor to access additional methods. \n",
    "\n",
    "In the following cell, we will use the `generate_coords` method to build coordinates for the `Xarray` dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_ds = ds.xref.generate_coords(time_dim_name=\"time\", x_dim_name=\"X\", y_dim_name=\"Y\")\n",
    "ref_ds = ref_ds.rename({\"0\": \"daily_rain\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_ds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kerchunk-cookbook-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
